
@article{schulte_to_buhne_better_2018,
	title = {Better together: {Integrating} and fusing multispectral and radar satellite imagery to inform biodiversity monitoring, ecological research and conservation science},
	volume = {9},
	issn = {2041-210X},
	shorttitle = {Better together},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12942},
	doi = {10.1111/2041-210X.12942},
	abstract = {The availability and accessibility of multispectral and radar satellite remote sensing (SRS) imagery are at an unprecedented high. These data have both become standard source of information for investigating species ecology and ecosystems structure, composition and function at large scales. Since they capture complementary aspects of the Earth's surface, synergies between these two types of imagery have the potential to greatly expand research and monitoring opportunities. However, despite the benefits of combining multispectral and radar SRS data, data fusion techniques, including image fusion, are not commonly used in biodiversity monitoring, ecology and conservation. To help close this application gap, we provide for the first time an overview of the most common SRS data fusion techniques, discussing their benefits and drawbacks, and pull together case studies illustrating the added value for biodiversity research and monitoring. Integrating and fusing multispectral and radar images can significantly improve our ability to assess the distribution as well as the horizontal and vertical structure of ecosystems. Additionally, SRS data fusion has the potential to increase opportunities for mapping species distribution and community composition, as well as for monitoring threats to biodiversity. Uptake of these techniques will benefit from more effective collaboration between remote sensing and biodiversity experts, making the reporting of methodologies more transparent, expanding SRS image processing capacity and promoting widespread open access to satellite imagery. In the context of a global biodiversity crisis, being able to track subtle changes in the biosphere across adequate spatial and temporal extents and resolutions is crucial. By making key parameter estimates derived from SRS data more accurate, SRS data fusion promises to become a powerful tool to help address current monitoring needs, and could support the development of essential biodiversity variables.},
	language = {en},
	number = {4},
	urldate = {2023-02-03},
	journal = {Methods in Ecology and Evolution},
	author = {Schulte to Bühne, Henrike and Pettorelli, Nathalie},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.12942},
	keywords = {image fusion, object-level fusion, pixel-level fusion, remote sensing of biodiversity, satellite data fusion},
	pages = {849--865},
	file = {Full Text PDF:D\:\\Zotero\\storage\\KVET6MZ3\\Schulte to Bühne 和 Pettorelli - 2018 - Better together Integrating and fusing multispect.pdf:application/pdf;Snapshot:D\:\\Zotero\\storage\\52KECAZS\\2041-210X.html:text/html},
}

@article{li_assessing_2021,
	title = {Assessing {Surface} {Water} {Flood} {Risks} in {Urban} {Areas} {Using} {Machine} {Learning}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4441},
	url = {https://www.mdpi.com/2073-4441/13/24/3520},
	doi = {10.3390/w13243520},
	abstract = {Urban flooding is a devastating natural hazard for cities around the world. Flood risk mapping is a key tool in flood management. However, it is computationally expensive to produce flood risk maps using hydrodynamic models. To this end, this paper investigates the use of machine learning for the assessment of surface water flood risks in urban areas. The factors that are considered in machine learning models include coordinates, elevation, slope gradient, imperviousness, land use, land cover, soil type, substrate, distance to river, distance to road, and normalized difference vegetation index. The machine learning models are tested using the case study of Exeter, UK. The performance of machine learning algorithms, including naïve Bayes, perceptron, artificial neural networks (ANNs), and convolutional neural networks (CNNs), is compared based on a spectrum of indicators, e.g., accuracy, F-beta score, and receiver operating characteristic curve. The results obtained from the case study show that the flood risk maps can be accurately generated by the machine learning models. The performance of models on the 30-year flood event is better than 100-year and 1000-year flood events. The CNNs and ANNs outperform the other machine learning algorithms tested. This study shows that machine learning can help provide rapid flood mapping, and contribute to urban flood risk assessment and management.},
	language = {en},
	number = {24},
	urldate = {2023-02-16},
	journal = {Water},
	author = {Li, Zhufeng and Liu, Haixing and Luo, Chunbo and Fu, Guangtao},
	month = jan,
	year = {2021},
	note = {Number: 24
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {machine learning, CNNs, deep learning, flood management, surface water flooding},
	pages = {3520},
	file = {Full Text PDF:D\:\\Zotero\\storage\\WQCBTXMU\\Li 等 - 2021 - Assessing Surface Water Flood Risks in Urban Areas.pdf:application/pdf},
}

@article{nair2018automated,
  title={Automated Image Annotation: A Survey},
  author={Nair, Rahul and Paul, P. J. and Jacob, K. Poulose},
  journal={Journal of Imaging},
  volume={4},
  number={3},
  pages={37},
  year={2018},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@misc{robison2018future,
  title={The Future of Image Annotation: Human in the Loop},
  author={Robison, Keela},
  year={2018},
  howpublished={\url{https://lionbridge.ai/articles/the-future-of-image-annotation-human-in-the-loop/}},
  note={Accessed: 28th Feb 2023}
}


@article{schulte_to_buhne_better_2018,
	title = {Better together: {Integrating} and fusing multispectral and radar satellite imagery to inform biodiversity monitoring, ecological research and conservation science},
	volume = {9},
	issn = {2041-210X},
	shorttitle = {Better together},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12942},
	doi = {10.1111/2041-210X.12942},
	abstract = {The availability and accessibility of multispectral and radar satellite remote sensing (SRS) imagery are at an unprecedented high. These data have both become standard source of information for investigating species ecology and ecosystems structure, composition and function at large scales. Since they capture complementary aspects of the Earth's surface, synergies between these two types of imagery have the potential to greatly expand research and monitoring opportunities. However, despite the benefits of combining multispectral and radar SRS data, data fusion techniques, including image fusion, are not commonly used in biodiversity monitoring, ecology and conservation. To help close this application gap, we provide for the first time an overview of the most common SRS data fusion techniques, discussing their benefits and drawbacks, and pull together case studies illustrating the added value for biodiversity research and monitoring. Integrating and fusing multispectral and radar images can significantly improve our ability to assess the distribution as well as the horizontal and vertical structure of ecosystems. Additionally, SRS data fusion has the potential to increase opportunities for mapping species distribution and community composition, as well as for monitoring threats to biodiversity. Uptake of these techniques will benefit from more effective collaboration between remote sensing and biodiversity experts, making the reporting of methodologies more transparent, expanding SRS image processing capacity and promoting widespread open access to satellite imagery. In the context of a global biodiversity crisis, being able to track subtle changes in the biosphere across adequate spatial and temporal extents and resolutions is crucial. By making key parameter estimates derived from SRS data more accurate, SRS data fusion promises to become a powerful tool to help address current monitoring needs, and could support the development of essential biodiversity variables.},
	language = {en},
	number = {4},
	urldate = {2023-02-03},
	journal = {Methods in Ecology and Evolution},
	author = {Schulte to Bühne, Henrike and Pettorelli, Nathalie},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.12942},
	keywords = {image fusion, object-level fusion, pixel-level fusion, remote sensing of biodiversity, satellite data fusion},
	pages = {849--865},
	file = {Full Text PDF:D\:\\Zotero\\storage\\KVET6MZ3\\Schulte to Bühne 和 Pettorelli - 2018 - Better together Integrating and fusing multispect.pdf:application/pdf;Snapshot:D\:\\Zotero\\storage\\52KECAZS\\2041-210X.html:text/html},
}

@inproceedings{Jensen1986IntroductoryDI,
  title={Introductory Digital Image Processing: A Remote Sensing Perspective},
  author={J. Robert Jensen},
  year={1986}
}

@article{maclachlan_sustainable_2021,
	title = {Sustainable {City} {Planning}: {A} {Data}-{Driven} {Approach} for {Mitigating} {Urban} {Heat}},
	volume = {6},
	issn = {2297-3362},
	shorttitle = {Sustainable {City} {Planning}},
	url = {https://www.frontiersin.org/articles/10.3389/fbuil.2020.519599},
	abstract = {Urban areas are expected to triple by 2030 in order to accommodate 60\% of the global population. Anthropogenic landscape modifications expand coverage of impervious surfaces inducing the urban heat island (UHI) effect, a critical twenty first century challenge associated with increased economic expenditure, energy consumption, and adverse health impacts. Yet, omission of UHI measures from global climate models and metropolitan planning methodologies precludes effective sustainable development governance. We present an approach that integrates Earth observation and climate data with three-dimensional urban models to determine optimal tree placement (per square meter) within proposed urban developments to enable more effective localized UHI mitigation. Such data-driven planning decisions will enhance the future sustainability of our cities to align with current global urban development agendas.},
	urldate = {2023-03-12},
	journal = {Frontiers in Built Environment},
	author = {MacLachlan, Andrew and Biggs, Eloise and Roberts, Gareth and Boruff, Bryan},
	year = {2021},
	file = {Full Text PDF:D\:\\Zotero\\storage\\EN7FBDZP\\MacLachlan 等 - 2021 - Sustainable City Planning A Data-Driven Approach .pdf:application/pdf},
}



@article{gorelick_google_2017,
	series = {Big {Remotely} {Sensed} {Data}: tools, applications and experiences},
	title = {Google {Earth} {Engine}: {Planetary}-scale geospatial analysis for everyone},
	volume = {202},
	issn = {0034-4257},
	shorttitle = {Google {Earth} {Engine}},
	url = {https://www.sciencedirect.com/science/article/pii/S0034425717302900},
	doi = {10.1016/j.rse.2017.06.031},
	abstract = {Google Earth Engine is a cloud-based platform for planetary-scale geospatial analysis that brings Google's massive computational capabilities to bear on a variety of high-impact societal issues including deforestation, drought, disaster, disease, food security, water management, climate monitoring and environmental protection. It is unique in the field as an integrated platform designed to empower not only traditional remote sensing scientists, but also a much wider audience that lacks the technical capacity needed to utilize traditional supercomputers or large-scale commodity cloud computing resources.},
	language = {en},
	urldate = {2023-03-14},
	journal = {Remote Sensing of Environment},
	author = {Gorelick, Noel and Hancher, Matt and Dixon, Mike and Ilyushchenko, Simon and Thau, David and Moore, Rebecca},
	month = dec,
	year = {2017},
	keywords = {Analysis, Big data, Cloud computing, Data democratization, Earth Engine, Platform},
	pages = {18--27},
	file = {ScienceDirect Full Text PDF:D\:\\Zotero\\storage\\NZ77554A\\Gorelick 等 - 2017 - Google Earth Engine Planetary-scale geospatial an.pdf:application/pdf;ScienceDirect Snapshot:D\:\\Zotero\\storage\\YW6K439E\\S0034425717302900.html:text/html},
}

@misc{google_machine_2023,
	title = {Machine {Learning} in {Earth} {Engine} {\textbar} {Google} {Earth} {Engine}},
	url = {https://developers.google.com/earth-engine/guides/machine-learning},
  author = {Google},
	year = {2023},
	language = {en},
	urldate = {2023-03-14},
	journal = {Google Developers},
	file = {Snapshot:D\:\\Zotero\\storage\\JU5WUHCP\\machine-learning.html:text/html},
}

@misc{google_reducer_2023,
	title = {Reducer {Overview} {\textbar} {Google} {Earth} {Engine}},
	url = {https://developers.google.com/earth-engine/guides/reducers_intro},
	language = {en},
	author = {Google},
	year = {2023},
	urldate = {2023-03-14},
	journal = {Google Developers},
	file = {Snapshot:D\:\\Zotero\\storage\\RWW6WQPQ\\reducers_intro.html:text/html},
}

@article{saad_el_imanni_multispectral_2023,
	title = {Multispectral {UAV} data for detection of weeds in a citrus farm using machine learning and {Google} {Earth} {Engine}: {Case} study of {Morocco}},
	volume = {30},
	issn = {2352-9385},
	shorttitle = {Multispectral {UAV} data for detection of weeds in a citrus farm using machine learning and {Google} {Earth} {Engine}},
	url = {https://www.sciencedirect.com/science/article/pii/S235293852300023X},
	doi = {10.1016/j.rsase.2023.100941},
	abstract = {Accurate and timely weed mapping between and within trees is considered one of the major challenges in the site-specific weed management systems. This research presents the first cloud computing approach based on the incorporation of multispectral Unmanned Aerial Vehicle (UAV) imagery in the Google Earth Engine (GEE) programming environment with the aim of improving the mapping of weed patches between and within trees in a citrus farm. For this purpose, the UAV multispectral bands (red, green, blue, near infrared, and red edge), as well as the estimated vegetation height from the UAV Digital Elevation Model (DEM) were analysed in terms of tree and weed discrimination and used as input into Random Forest (RF) and k-nearest neighbors (KNN) machine learning algorithms. From the DEM, the Digital Terrain Model (DTM) was estimated using the Inverse Distance Weighted Interpolation (IDW) of the elevation values of dense points on the soil. The plant height was derived by subtracting the DTM from the DEM, resulting in the Canopy Height Model (CHM). The experimental results show that: (i) the combination of spectral bands and the CHM can classify both trees and weeds with an overall accuracy reached 96.87\%; (ii) the RF classifier was more robust compared to KNN in the classification performance; (iii) when compared to the use of UAV spectral bands, the addition of the CHM can improve the accuracy of crop classification by 13.36\% (KNN) and 1.79\% (RF). Furthermore, the integration of UAV imagery in the GEE was highly efficient in terms of automation of the UAV imagery processing.},
	language = {en},
	urldate = {2023-03-14},
	journal = {Remote Sensing Applications: Society and Environment},
	author = {Saad El Imanni, Hajar and El Harti, Abderrazak and Bachaoui, El Mostafa and Mouncif, Hicham and Eddassouqui, Fatine and Hasnai, Mohamed Achraf and Zinelabidine, Moulay Ismail},
	month = apr,
	year = {2023},
	keywords = {Canopy height model (CHM), Google earth engine (GEE), Machine learning, Multispectral UAV imagery, Weed mapping},
	pages = {100941},
	file = {ScienceDirect Snapshot:D\:\\Zotero\\storage\\8PIR2GSZ\\S235293852300023X.html:text/html},
}

@incollection{gokce_wetland_2019,
	title = {Wetland {Monitoring} and {Mapping} {Using} {Synthetic} {Aperture} {Radar}},
	isbn = {978-1-78985-013-0 978-1-78985-014-7},
	url = {https://www.intechopen.com/books/wetlands-management-assessing-risk-and-sustainable-solutions/wetland-monitoring-and-mapping-using-synthetic-aperture-radar},
	abstract = {Wetlands are critical for ensuring healthy aquatic systems, preventing soil erosion, and securing groundwater reservoirs. Also, they provide habitat for many animal and plant species. Thus, the continuous monitoring and mapping of wetlands is necessary for observing effects of climate change and ensuring a healthy environment. Synthetic Aperture Radar (SAR) remote sensing satellites are active remote sensing instruments essential for monitoring wetlands, given the possibility to bypass the cloud-sensitive optical instruments and obtain satellite imagery day and night. Therefore, the purpose of this chapter is to provide an overview of the basic concepts of SAR remote sensing technology and its applications for wetland monitoring and mapping. Emphasis is given to SAR systems with full and compact polarimetric SAR capabilities. Brief discussions on the latest stateof-the-art wetland applications using SAR imagery are presented. Also, we summarize the current trends in wetland monitoring and mapping using SAR imagery. This chapter provides a good introduction to interested readers with limited background in SAR technology and its possible wetland applications.},
	language = {en},
	urldate = {2023-03-23},
	booktitle = {Wetlands {Management} - {Assessing} {Risk} and {Sustainable} {Solutions}},
	publisher = {IntechOpen},
	author = {Dabboor, Mohammed and Brisco, Brian},
	editor = {Gökçe, Didem},
	month = jan,
	year = {2019},
	doi = {10.5772/intechopen.80224},
	file = {Dabboor 和 Brisco - 2019 - Wetland Monitoring and Mapping Using Synthetic Ape.pdf:D\:\\Zotero\\storage\\3XCKJB2W\\Dabboor 和 Brisco - 2019 - Wetland Monitoring and Mapping Using Synthetic Ape.pdf:application/pdf},
}


@incollection{gokce_wetland_2019,
	title = {Wetland {Monitoring} and {Mapping} {Using} {Synthetic} {Aperture} {Radar}},
	isbn = {978-1-78985-013-0 978-1-78985-014-7},
	url = {https://www.intechopen.com/books/wetlands-management-assessing-risk-and-sustainable-solutions/wetland-monitoring-and-mapping-using-synthetic-aperture-radar},
	abstract = {Wetlands are critical for ensuring healthy aquatic systems, preventing soil erosion, and securing groundwater reservoirs. Also, they provide habitat for many animal and plant species. Thus, the continuous monitoring and mapping of wetlands is necessary for observing effects of climate change and ensuring a healthy environment. Synthetic Aperture Radar (SAR) remote sensing satellites are active remote sensing instruments essential for monitoring wetlands, given the possibility to bypass the cloud-sensitive optical instruments and obtain satellite imagery day and night. Therefore, the purpose of this chapter is to provide an overview of the basic concepts of SAR remote sensing technology and its applications for wetland monitoring and mapping. Emphasis is given to SAR systems with full and compact polarimetric SAR capabilities. Brief discussions on the latest stateof-the-art wetland applications using SAR imagery are presented. Also, we summarize the current trends in wetland monitoring and mapping using SAR imagery. This chapter provides a good introduction to interested readers with limited background in SAR technology and its possible wetland applications.},
	language = {en},
	urldate = {2023-03-23},
	booktitle = {Wetlands {Management} - {Assessing} {Risk} and {Sustainable} {Solutions}},
	publisher = {IntechOpen},
	author = {Dabboor, Mohammed and Brisco, Brian},
	editor = {Gökçe, Didem},
	month = jan,
	year = {2019},
	doi = {10.5772/intechopen.80224},
	file = {Dabboor 和 Brisco - 2019 - Wetland Monitoring and Mapping Using Synthetic Ape.pdf:D\:\\Zotero\\storage\\3XCKJB2W\\Dabboor 和 Brisco - 2019 - Wetland Monitoring and Mapping Using Synthetic Ape.pdf:application/pdf},
}


@article{dubeau_mapping_2017,
	title = {Mapping the {Dabus} {Wetlands}, {Ethiopia}, {Using} {Random} {Forest} {Classification} of {Landsat}, {PALSAR} and {Topographic} {Data}},
	volume = {9},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/9/10/1056},
	doi = {10.3390/rs9101056},
	abstract = {The Dabus Wetland complex in the highlands of Ethiopia is within the headwaters of the Nile Basin and is home to significant ecological communities and rare or endangered species. Its many interrelated wetland types undergo seasonal and longer-term changes due to weather and climate variations as well as anthropogenic land use such as grazing and burning. Mapping and monitoring of these wetlands has not been previously undertaken due primarily to their relative isolation and lack of resources. This study investigated the potential of remote sensing based classification for mapping the primary vegetation groups in the Dabus Wetlands using a combination of dry and wet season data, including optical (Landsat spectral bands and derived vegetation and wetness indices), radar (ALOS PALSAR L-band backscatter), and elevation (SRTM derived DEM and other terrain metrics) as inputs to the non-parametric Random Forest (RF) classifier. Eight wetland types and three terrestrial/upland classes were mapped using field samples of observed plant community composition and structure groupings as reference information. Various tests to compare results using different RF input parameters and data types were conducted. A combination of multispectral optical, radar and topographic variables provided the best overall classification accuracy, 94.4\% and 92.9\% for the dry and wet season, respectively. Spectral and topographic data (radar data excluded) performed nearly as well, while accuracies using only radar and topographic data were 82–89\%. Relatively homogeneous classes such as Papyrus Swamps, Forested Wetland, and Wet Meadow yielded the highest accuracies while spatially complex classes such as Emergent Marsh were more difficult to accurately classify. The methods and results presented in this paper can serve as a basis for development of long-term mapping and monitoring of these and other non-forested wetlands in Ethiopia and other similar environmental settings.},
	number = {10},
	journal = {Remote Sensing},
	author = {Dubeau, Pierre and King, Douglas J. and Unbushe, Dikaso Gojamme and Rebelo, Lisa-Maria},
	year = {2017},
}

@article{jahncke_mapping_2018,
	title = {Mapping wetlands in {Nova} {Scotia} with multi-beam {RADARSAT}-2 {Polarimetric} {SAR}, optical satellite imagery, and {Lidar} data},
	volume = {68},
	issn = {1569-8432},
	url = {https://www.sciencedirect.com/science/article/pii/S0303243418300801},
	doi = {10.1016/j.jag.2018.01.012},
	abstract = {Wetland maps currently in use by the Province of Nova Scotia, namely the Department of Natural Resources (DNR) wetland inventory map and the swamp wetland classes of the DNR forest map, need to be updated. In this study, wetlands were mapped in an area southwest of Halifax, Nova Scotia by classifying a combination of multi-date and multi-beam RADARSAT-2 C-band polarimetric SAR (polSAR) images with spring Lidar, and fall QuickBird optical data using the Random Forests (RF) classifier. The resulting map has five wetland classes (open-water/marsh complex, open bog, open fen, shrub/treed fen/bog, swamp), plus lakes and various upland classes. Its accuracy was assessed using data from 156 GPS wetland sites collected in 2012 and compared to the one obtained with the current wetland map of Nova Scotia. The best overall classification was obtained using a combination of Lidar, RADARSAT-2 HH, HV, VH, VV intensity with polarimetric variables, and QuickBird multispectral (89.2\%). The classified image was compared to GPS validation sites to assess the mapping accuracy of the wetlands. It was first done considering a group consisting of all wetland classes including lakes. This showed that only 69.9\% of the wetland sites were correctly identified when only the QuickBird classified image was used in the classification. With the addition of variables derived from lidar, the number of correctly identified wetlands increased to 88.5\%. The accuracy remained the same with the addition of RADARSAT-2 (88.5\%). When we tested the accuracy for identifying wetland classes (e.g. marsh complex vs. open bog) instead of grouped wetlands, the resulting wetland map performed best with either QuickBird and Lidar, or QuickBird, Lidar, and RADARSAT-2 (66\%). The Province of Nova Scotia’s current wetland inventory and its associated wetland classes (aerial-photo interpreted) were also assessed against the GPS wetland sites. This provincial inventory correctly identified 62.2\% of the grouped wetlands and only 18.6\% of the wetland classes. The current inventory’s poor performance demonstrates the value of incorporating a combination of new data sources into the provincial wetland mapping.},
	language = {en},
	urldate = {2023-03-23},
	journal = {International Journal of Applied Earth Observation and Geoinformation},
	author = {Jahncke, Raymond and Leblon, Brigitte and Bush, Peter and LaRocque, Armand},
	month = jun,
	year = {2018},
	keywords = {Lidar, Polarimetric SAR, QuickBird, Random forests classification, Wetlands},
	pages = {139--156},
	file = {ScienceDirect Full Text PDF:D\:\\Zotero\\storage\\VWWX4RUI\\Jahncke 等 - 2018 - Mapping wetlands in Nova Scotia with multi-beam RA.pdf:application/pdf;ScienceDirect Snapshot:D\:\\Zotero\\storage\\KJ3HN2DH\\S0303243418300801.html:text/html},
}


@article{millard_wetland_2013,
	title = {Wetland mapping with {LiDAR} derivatives, {SAR} polarimetric decompositions, and {LiDAR}–{SAR} fusion using a random forest classifier},
	volume = {39},
	issn = {0703-8992},
	url = {https://doi.org/10.5589/m13-038},
	doi = {10.5589/m13-038},
	abstract = {In this paper, we assess the use of Random Forest (RF) for mapping land cover classes within Mer Bleue bog, a large northern peatland in southeastern Ontario near Ottawa, Canada, using Synthetic Aperture Radar (SAR) and airborne Light Detection and Ranging (LiDAR). Not only has RF been shown to improve classification accuracies over more traditional classifiers, but it also provides useful information on the statistical importance of individual input image bands for land cover classification. Our specific objectives in this study were to: (i) assess the robustness of a RF approach to northern peatland classification; (ii) examine variable importance resulting from the RF classifications to identify which imagery types, derivatives, and analysis scales are most useful for mapping different classes of northern peatlands; (iii) assess if fusion of different LiDAR and SAR variables can improve classification accuracies at Mer Bleue; and (iv) assess physical interpretability of the multisensor image types and derivatives with respect to biophysical attributes associated with peatland classes. Our results show that the fusion of SAR with LiDAR imagery and derivatives at this study site did not provide additional classification accuracy over the use of LiDAR derivatives alone. Nevertheless, the RF-based approach presented here has strong potential to improve mapping and imagery classification of wetlands and may also help researchers and practitioners improve information extraction and land cover classification in other application areas benefitting from large volumes of multi-sensor imagery.},
	number = {4},
	urldate = {2023-03-23},
	journal = {Canadian Journal of Remote Sensing},
	author = {Millard, Koreen and Richardson, Murray},
	month = oct,
	year = {2013},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.5589/m13-038},
	pages = {290--307},
	file = {Full Text PDF:D\:\\Zotero\\storage\\XK7MW96R\\Millard 和 Richardson - 2013 - Wetland mapping with LiDAR derivatives, SAR polari.pdf:application/pdf},
}

